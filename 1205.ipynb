{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train big dataset on 2 gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the necesary json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./projects/TridentNet_5class/xml2coco.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./projects/TridentNet_5class/xml2coco.py\n",
    "from lxml import etree\n",
    "import json\n",
    "import os\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# def xml2dicts(anno_dir,file,anno_id,categories_list):\n",
    "# def xml2dicts(anno_dir,img_dir,file,anno_id,categories_list,y):\n",
    "def xml2dicts(anno_dir,img_dir,file,anno_id,categories_list):\n",
    "    '''\n",
    "    Used by function `split_dataset', \n",
    "    Convert the xml annotation file into the format function `split_dataset' accept\n",
    "    Args:\n",
    "        anno_dir(string): the path of the dataset annitations, e.g. 'simdata/val/Annotations'\n",
    "        img_dir(string): the path of the dataset images, \n",
    "            to read the image shape\n",
    "            (hardcoded as (380,190) in xml files but that's not ture)\n",
    "        file: the filename of the xml annotation file\n",
    "        anno_id: the annotation id of the first annotation\n",
    "        categories_list: the list of the categories\n",
    "    Returns:\n",
    "        tuple: the tuple contains 1 dictionary, 1 list and 1 int:\n",
    "            dictionary: the image dictionary in COCO format\n",
    "            list: the list of the annotation dictionaries in COCO format\n",
    "            e.g. ({image_dict}, [{anno_dict1}, {anno_dict2}, ...])\n",
    "    '''\n",
    "    img_record = {}\n",
    "    \n",
    "    img_name = file[:-3]+'jpg'\n",
    "    \n",
    "    image_id = ''\n",
    "    for i in filter(str.isdigit, img_name):\n",
    "        image_id += i\n",
    "    img_record['file_name'] = img_name\n",
    "    img_record['id']=int(image_id)\n",
    "    \n",
    "#     if img_name in y:\n",
    "#         img_record['width'] = 380\n",
    "#         img_record['height'] = 760\n",
    "#     else:\n",
    "    img_record['width'] = 190\n",
    "    img_record['height'] = 380\n",
    "#     img = mpimg.imread(os.path.join(img_dir, img_name))\n",
    "#     (height, width) =  img.shape\n",
    "#     img_record['width'] = width\n",
    "#     img_record['height'] = height\n",
    "             \n",
    "    tree=etree.parse(os.path.join(anno_dir,file))\n",
    "    root=tree.getroot()\n",
    "    bboxes=[]\n",
    "    for c in root.iter():\n",
    "        if c.tag=='object':\n",
    "            bboxes.append(c)\n",
    "    \n",
    "    annotations = []           \n",
    "    for bbox in bboxes:\n",
    "        anno_record ={}\n",
    "        anno_record['id'] = anno_id\n",
    "        anno_id += 1\n",
    "        anno_record['image_id'] = img_record['id']\n",
    "        anno_record['iscrowd'] = 0\n",
    "        box=[]\n",
    "        for b in bbox.iter(): \n",
    "            if b.tag == 'name':\n",
    "                anno_record['category_id'] = categories_list.index(b.text)\n",
    "            elif b.tag == 'xmin':\n",
    "                xmin = int(b.text)-1\n",
    "            elif b.tag == 'ymin':\n",
    "                ymin = int(b.text)-1\n",
    "            elif b.tag == 'xmax':\n",
    "                xmax = int(b.text)-1\n",
    "            elif b.tag == 'ymax':\n",
    "                ymax = int(b.text)-1\n",
    "        if file[:5]=='Train':\n",
    "            xmin = int(xmin/2)\n",
    "            ymin = int(ymin/2)\n",
    "            xmax = int(xmax/2)\n",
    "            ymax = int(ymax/2)\n",
    "        width = xmax - xmin +1\n",
    "        height = ymax - ymin + 1\n",
    "        anno_record['bbox'] = [xmin, ymin, width, height]\n",
    "        anno_record['area'] = float(width*height)\n",
    "        annotations.append(anno_record)\n",
    "    return img_record, annotations\n",
    "    \n",
    "def split_dataset(anno_dir, img_dir, output_dir = None):\n",
    "    '''\n",
    "    Convert the xml dataset annotations into 2 COCO format ground truth [train, test] annotations json files,\n",
    "    so as to call `COCOEvaluator` and function `register_coco_instances`\n",
    "    Args:\n",
    "        anno_dir(string): the path of the dataset annitations, e.g. 'simdata/val/Annotations'\n",
    "        img_dir(string): the path of the dataset images, to make sure that there is a image corresponding to the xml file\n",
    "        output_dir(string): the directory to save the 2 json files: train_anno.json & test_anno.json\n",
    "    '''\n",
    "#     with open('./projects/TridentNet_5class/dataset/big_image_760x380.txt', 'r') as f:\n",
    "#         x = f.readlines()\n",
    "#     y = []\n",
    "#     for i in x:\n",
    "#         y.append(i[:-27])\n",
    "        \n",
    "    xml_files=os.listdir(anno_dir)\n",
    "    img_files=os.listdir(img_dir)\n",
    "    \n",
    "    json_train = {}\n",
    "    json_test = {}\n",
    "    \n",
    "    categories = []\n",
    "    categories_list = ['gun', 'knife', 'cellphone', 'explosive', 'object']\n",
    "    for i,j in enumerate(categories_list):\n",
    "        category_dict = {}\n",
    "        category_dict['id'] = i\n",
    "        category_dict['name'] = j\n",
    "        categories.append(category_dict)\n",
    "    json_train['categories'] = categories\n",
    "    json_test['categories'] = categories\n",
    "    \n",
    "    train_images = []\n",
    "    test_images = []\n",
    "\n",
    "    train_annotations = []\n",
    "    test_annotations = []\n",
    "    \n",
    "    anno_id = 0\n",
    "    for file in xml_files:\n",
    "        # becasue I'm using Jupyterlab\n",
    "        # which always creates the boring cache file/directory\n",
    "        if not file[-3:] == 'xml':\n",
    "            continue\n",
    "        elif file[:-3]+'jpg' not in img_files:\n",
    "            continue\n",
    "        elif file[:8] == 'Train_12':\n",
    "            anno_single_file = xml2dicts(anno_dir,img_dir,file,anno_id,categories_list)\n",
    "            test_images.append(anno_single_file[0])\n",
    "            test_annotations.extend(anno_single_file[1])\n",
    "            anno_id += len(anno_single_file[1])\n",
    "        else:\n",
    "            anno_single_file = xml2dicts(anno_dir,img_dir,file,anno_id,categories_list)\n",
    "            train_images.append(anno_single_file[0])\n",
    "            train_annotations.extend(anno_single_file[1])\n",
    "            anno_id += len(anno_single_file[1])\n",
    "            \n",
    "    json_train['images'] = train_images\n",
    "    json_test['images'] = test_images\n",
    "    json_train['annotations'] = train_annotations\n",
    "    json_test['annotations'] = test_annotations\n",
    "    \n",
    "    json_train_file = json.dumps(json_train)\n",
    "    json_test_file = json.dumps(json_test)\n",
    "    if output_dir == None:\n",
    "        output_dir = anno_dir\n",
    "    with open(os.path.join(output_dir,'train_annotations.json'),'w') as f:\n",
    "        f.write(json_train_file)\n",
    "    with open(os.path.join(output_dir,'test_annotations.json'),'w') as f:\n",
    "        f.write(json_test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from luckyDiary.projects.TridentNet_5class.xml2coco import split_dataset\n",
    "split_dataset('../sim_data_center/multi_class_detection/down/Annotations','../sim_data_center/multi_class_detection/down/JPEGImages','./projects/TridentNet_5class/dataset/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./projects/TridentNet_5class/train_net.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./projects/TridentNet_5class/train_net.py\n",
    "import os\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.config import CfgNode as CN\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.config import get_cfg\n",
    "from projects.TridentNet.tridentnet import add_tridentnet_config\n",
    "from detectron2.engine import default_setup, DefaultTrainer, default_argument_parser, launch\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.evaluation import COCOEvaluator, verify_results\n",
    "import detectron2.utils.comm as comm\n",
    "\n",
    "class Trainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
    "        return COCOEvaluator(dataset_name, cfg, True, output_folder)\n",
    "\n",
    "def setup(args):\n",
    "    \"\"\"\n",
    "    Create configs and perform basic setups.\n",
    "    \"\"\"\n",
    "    cfg = get_cfg()\n",
    "    add_tridentnet_config(cfg)\n",
    "    cfg.merge_from_file(args.config_file)\n",
    "    cfg.merge_from_list(args.opts)\n",
    "    cfg.MODEL.PIXEL_MEAN = [28, 28, 28]\n",
    "    cfg.MODEL.RPN.IOU_THRESHOLDS = [0.05, 0.3]\n",
    "    cfg.MODEL.ROI_HEADS.IOU_THRESHOLDS = [0.3]\n",
    "    cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[8,16,32,64,128]]\n",
    "    cfg.SOLVER.MAX_ITER = 1200000\n",
    "    cfg.DATASETS.TRAIN = ('sim_multi_train',)\n",
    "    cfg.DATASETS.TEST = ('sim_multi_test',)\n",
    "    cfg.INPUT.CROP = CN({\"ENABLED\": True})\n",
    "    cfg.INPUT.CROP.TYPE = \"relative_range\"\n",
    "    cfg.INPUT.CROP.SIZE = [0.75, 0.95]\n",
    "    cfg.TEST.EVAL_PERIOD = 50000\n",
    "    cfg.MODEL.WEIGHTS = './output/model_1054999.pth'\n",
    "    cfg.SOLVER.BASE_LR = 0.0025\n",
    "    cfg.freeze()\n",
    "    default_setup(cfg, args)\n",
    "    return cfg\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    # register the datasets\n",
    "#     register_coco_instances('sim_multi_train', {},\\\n",
    "#                         '../../small_multi/train_annotations.json', \\\n",
    "#                         '../../../sim_data_center/multi_class_detection/down/JPEGImages/')\n",
    "#     register_coco_instances('sim_multi_test', {},\\\n",
    "#                         '../../small_multi/test_annotations.json', \\\n",
    "#                         '../../../sim_data_center/multi_class_detection/down/JPEGImages/')\n",
    "    register_coco_instances('sim_multi_train', {},\\\n",
    "                        './dataset/train_annotations.json', \\\n",
    "                        '../../../sim_data_center/multi_class_detection/down/JPEGImages/')\n",
    "    register_coco_instances('sim_multi_test', {},\\\n",
    "                        './dataset/test_annotations.json', \\\n",
    "                        '../../../sim_data_center/multi_class_detection/down/JPEGImages/')\n",
    "#     register_coco_instances('sim_multi_train', {},\\\n",
    "#                         './projects/TridentNet_5class/dataset/train_annotations.json', \\\n",
    "#                         '../sim_data_center/multi_class_detection/down/JPEGImages/')\n",
    "#     register_coco_instances('sim_multi_test', {},\\\n",
    "#                         './projects/TridentNet_5class/dataset/test_annotations.json', \\\n",
    "#                         '../sim_data_center/multi_class_detection/down/JPEGImages/')\n",
    "    cfg = setup(args)\n",
    "\n",
    "    if args.eval_only:\n",
    "        model = Trainer.build_model(cfg)\n",
    "        cfg.defrost()\n",
    "        cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "#         cfg.MODEL.RPN.IOU_THRESHOLDS = [0.05, 0.3]\n",
    "#         cfg.MODEL.ROI_HEADS.IOU_THRESHOLDS = [0.2]\n",
    "        cfg.freeze()\n",
    "        DetectionCheckpointer(model, save_dir=cfg.OUTPUT_DIR).resume_or_load(\n",
    "            cfg.MODEL.WEIGHTS, resume=args.resume\n",
    "        )\n",
    "        res = Trainer.test(cfg, model)\n",
    "        if comm.is_main_process():\n",
    "            verify_results(cfg, res)\n",
    "        return res\n",
    "\n",
    "    trainer = Trainer(cfg)\n",
    "    trainer.resume_or_load(resume=args.resume)\n",
    "    return trainer.train()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # specify the gpus to use\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '2,3'\n",
    "    args = default_argument_parser().parse_args()\n",
    "    print(\"Command Line Args:\", args)\n",
    "    launch(\n",
    "        main,\n",
    "        args.num_gpus,\n",
    "        num_machines=args.num_machines,\n",
    "        machine_rank=args.machine_rank,\n",
    "        dist_url=args.dist_url,\n",
    "        args=(args,),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(21.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(43/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(4.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(4.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(4.51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(4.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
