{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **æ˜¨å¤©æ²¡èµ°å®Œ**ï¼Œä»Šå¤©ç»§ç»­æ ¹æ®PyTorchæ•™ç¨‹ä¸­çš„60min Blitzèµ°ä¸€é­\n",
    "#### *ç»“æœä»Šå¤©æ‘¸äº†ä¸€æ•´å¤©çš„ğŸŸ*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is PyTorch?\n",
    "#### Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from \\_\\_future__ import print_function ä½¿å¾—åœ¨Python 2ä¸­printå‡½æ•°ä¹Ÿå¾—åŠ ï¼ˆï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.view: *resize/reshape tensor*, å‚æ•°-1è¡¨ç¤ºè¯¥å‚æ•°ç”±ç»´åº¦æ¨æ–­å¾—æ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1815, -0.6658, -0.1449,  0.9833],\n",
      "        [ 0.3941, -0.3346,  0.9866, -0.3663],\n",
      "        [ 0.5880,  0.0405,  0.0253,  1.5809],\n",
      "        [-0.3907,  0.3668,  0.8283,  0.3876]])\n",
      "tensor([ 0.1815, -0.6658, -0.1449,  0.9833,  0.3941, -0.3346,  0.9866, -0.3663,\n",
      "         0.5880,  0.0405,  0.0253,  1.5809, -0.3907,  0.3668,  0.8283,  0.3876])\n",
      "tensor([[ 0.1815, -0.6658, -0.1449,  0.9833,  0.3941, -0.3346,  0.9866, -0.3663],\n",
      "        [ 0.5880,  0.0405,  0.0253,  1.5809, -0.3907,  0.3668,  0.8283,  0.3876]])\n",
      "tensor([[ 0.1815, -0.6658, -0.1449,  0.9833,  0.3941, -0.3346,  0.9866, -0.3663,\n",
      "          0.5880,  0.0405,  0.0253,  1.5809, -0.3907,  0.3668,  0.8283,  0.3876]])\n"
     ]
    }
   ],
   "source": [
    "x=torch.randn(4,4)\n",
    "y=x.view(16)\n",
    "z=x.view(-1,8)\n",
    "t=x.view(1,-1)\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4]) torch.Size([3, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "m=torch.randn(2,3,4)\n",
    "n=m.view(-1,2,4)\n",
    "print(m.size(), n.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¯¹äºåªæœ‰ä¸€ä¸ªå…ƒç´ çš„tensorï¼Œä½¿ç”¨.item()å¯ä»¥è·å–è¯¥å…ƒç´ çš„å€¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2182])\n",
      "1.218241572380066\n"
     ]
    }
   ],
   "source": [
    "x=torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.4541)\n",
      "-0.45413321256637573\n"
     ]
    }
   ],
   "source": [
    "y=torch.randn(2,4)\n",
    "print(y[1,3])\n",
    "print(y[1,3].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numpy Bridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Torch tensorä¸numpy arrayå…±äº«åº•å±‚å†…å­˜åœ°å€ï¼ˆ*å¦‚æœtorch tensorä½äºCPU*ï¼‰ï¼Œä¿®æ”¹ä¸€ä¸ªå°†ä¼šå¯¼è‡´å¦ä¸€ä¸ªå˜åŒ–"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å°†torch tensorè½¬æ¢ä¸ºnumpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "a=torch.ones(5)\n",
    "print(a)\n",
    "b=a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¿®æ”¹å…¶ä¸­ä¸€ä¸ªä¼šå¯¼è‡´å¦ä¸€ä¸ªå˜åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3., 3.])\n",
      "[3. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(2)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å°†numpy arrayè½¬æ¢ä¸ºtorch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 3. 3. 3.]\n",
      "tensor([3., 3., 3., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a=np.zeros(4)\n",
    "b=torch.from_numpy(a)\n",
    "np.add(a,3,out=a)\n",
    "print(a)\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CUDA Tensors\n",
    "å¯ä»¥åˆ©ç”¨.toæ–¹æ³•å°†tensorsç§»åŠ¨åˆ°å¦‚ä½•device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 2, 2],\n",
      "        [2, 2, 2]], device='cuda:0')\n",
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# ä½¿ç”¨torch.deviceå¯¹è±¡å°†tensorç§»å…¥æˆ–ç§»å‡ºGPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\") #deviceæ˜¯ä¸€ä¸ªtorch.deviceå¯¹è±¡\n",
    "    y = torch.ones_like(x,device=device) # ç›´æ¥åœ¨GPUåˆ›å»ºtensor\n",
    "    x = x.to(device) # æˆ–è€…ç›´æ¥ç”¨to(\"cuda\")\n",
    "    z = x + y\n",
    "#     a = torch.randn(1)\n",
    "#     s = a + y\n",
    "#     ç›´æ¥å°†cpuä¸­çš„tensorä¸gpuä¸­çš„tensorä¼šæŠ¥é”™\n",
    "#     æŠ¥é”™å†…å®¹:expected device cpu and dtype Float but got device cuda:0 and dtype Long\n",
    "#     å› ä¸º_th_normal_ not supported on CPUType for Long\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double)) # .toæ–¹æ³•ä¹Ÿèƒ½åŒæ—¶æ”¹å˜dtype\n",
    "#     print(s)\n",
    "#     print(s.to(\"cuda\"))\n",
    "#     print(s.to(\"cpu\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
